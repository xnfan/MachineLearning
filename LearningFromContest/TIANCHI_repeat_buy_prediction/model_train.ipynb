{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv(\"data/train_all.csv\", nrows=10000)\n",
    "test_data = pd.read_csv(\"data/test_all.csv\", nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "features_columns = [col for col in train_data.columns if col not in ['user_id', \"label\"]]\n",
    "train = train_data[features_columns].values\n",
    "test = test_data[features_columns].values\n",
    "target = train_data['label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 229) (1200,)\n",
      "(800, 229) (800,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9275"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,\n",
    "                             max_depth=2,\n",
    "                             random_state=0,\n",
    "                             n_jobs=-1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train, target, test_size=0.4, random_state=0\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9375 0.935  0.935  0.935  0.935 ]\n",
      "Accuracy: 0.94 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,\n",
    "                             max_depth=2,\n",
    "                             random_state=0,\n",
    "                             n_jobs=-1)\n",
    "scores = cross_val_score(clf, train, target, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48387097 0.48320413 0.48320413 0.48320413 0.48320413]\n",
      "Accuracy: 0.48 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,\n",
    "                             max_depth=2,\n",
    "                             random_state=0,\n",
    "                             n_jobs=-1)\n",
    "scores = cross_val_score(clf, train, target, cv=5, scoring=\"f1_macro\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92833333 0.94       0.94166667 0.93       0.93166667]\n",
      "Accuracy: 0.93 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,\n",
    "                             max_depth=2,\n",
    "                             random_state=0,\n",
    "                             n_jobs=-1)\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "scores = cross_val_score(clf, train, target, cv=cv)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9375\n",
      "1 0.925\n",
      "2 0.935\n",
      "3 0.9325\n",
      "4 0.9475\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,\n",
    "                             max_depth=2,\n",
    "                             random_state=0,\n",
    "                             n_jobs=-1)\n",
    "kf = KFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    X_train, X_test, y_train, y_test = train[train_index], train[test_index], target[train_index], target[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(k, clf.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9375\n",
      "1 0.935\n",
      "2 0.935\n",
      "3 0.935\n",
      "4 0.935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,\n",
    "                             max_depth=2,\n",
    "                             random_state=0,\n",
    "                             n_jobs=-1)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(skf.split(train, target)):\n",
    "    X_train, X_test, y_train, y_test = train[train_index], train[test_index], target[train_index], target[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(k, clf.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 50}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.471 (+/-0.002) for {'n_estimators': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "the model is trained on the full development set.\n",
      "the scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96       928\n",
      "         1.0       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.92      1000\n",
      "   macro avg       0.46      0.49      0.48      1000\n",
      "weighted avg       0.86      0.92      0.89      1000\n",
      "\n",
      "\n",
      "0.471 (+/-0.002) for {'n_estimators': 100}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "the model is trained on the full development set.\n",
      "the scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96       928\n",
      "         1.0       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.92      1000\n",
      "   macro avg       0.46      0.49      0.48      1000\n",
      "weighted avg       0.86      0.92      0.89      1000\n",
      "\n",
      "\n",
      "0.471 (+/-0.002) for {'n_estimators': 200}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "the model is trained on the full development set.\n",
      "the scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96       928\n",
      "         1.0       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.92      1000\n",
      "   macro avg       0.46      0.49      0.48      1000\n",
      "weighted avg       0.86      0.92      0.89      1000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 模型调参\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.5, random_state=0)\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "tuned_parameters = {\"n_estimators\": [50, 100, 200]}\n",
    "\n",
    "scores = ['precision']\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(clf, tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.3f) for %r\" % (mean, std*2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"the model is trained on the full development set.\")\n",
    "        print(\"the scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[464   3]\n",
      " [ 33   0]]\n",
      "Normalized confusion matrix\n",
      "[[0.99 0.01]\n",
      " [1.   0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEYCAYAAAAgU193AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAoeklEQVR4nO3debxVZdnG8d91DoMoIJpDDhgOaIpjzuZAOeGQWmri9DpmlmW+aqVlZg5p1puaaWppYeaYpaipKDmnIZMmmIGhiaKCU4og0/3+sZ6Di805e29gnz1xffnsz9lrvvd080xrLUUEZmb2sZZaB2BmVm+cGM3MCjgxmpkVcGI0MyvgxGhmVsCJ0cysgBNjmST1kHSXpPck3bYE+zlc0rBKxlYrknaS9EK9HE9SP0khqUu1YmoEhe+LpHslHdUJxxknaWCl91sLarZxjJIOA04FPg28D4wFLoiIx5dwv0cC3wR2iIg5SxpnvZMUQP+ImFjrWDoi6SXg+Ih4ME33AyYBXSv9GUn6HTA5Is6q5H6roTPel0Z+P8rRVCVGSacClwI/BlYF1gKuBPavwO4/BfxraUiK5XCprPP4va0DEdEUD2B54APg4CLrdCdLnK+lx6VA97RsIDAZOA14E5gCHJOW/QiYBcxOxzgOOAe4IbfvfkAAXdL00cC/yUqtk4DDc/Mfz223A/A08F76u0Nu2cPAecATaT/DgJU6eG1t8X8nF/8BwN7Av4C3ge/l1t8GeBJ4N637S6BbWvZoei3T0+s9JLf/7wKvA79vm5e2WTcd4zNpenVgGjCwjM9uCHBaer5GOvbX0/R6ab8qON7vgXnAjBTjd3KfwVHAf9Lxv1/m57/A55LmRTr+Cemzn5WOdVcHryOAE4EJwDvAFXxcK2sBzgJeTp/P9cDyBd+d41Lcj6Z4ngAuSZ/Rv8m+K0cDr6R9HJU79j7AGOC/afk5Rb6bD5OVtAGeSa+p7RFtnxlwW/qs30sxDUjz230/gJeA3Zbkt1Yvj5oHULEXAoOAOW0ffgfrnAs8BawCrAz8DTgv92HNSet0JUsoHwIrpOXnsGAiLJye/+UDlktf0A3SstVyX6qjST9AYEWyH9CRabtD0/Qncl/gF4H1gR5p+qIOXltb/Gen+L8CTAVuBHoBA4CZwDpp/S2B7dJx+wHPA6cU/MjXa2f/P0lf+h7kElVa5ytpP8sC9wM/K/OzOzb34zosveZbcsvuzP+gctu9RPohFnwGv07xbQZ8BGxYxuc//3Np7z0AfgecX+J1BHA30IestjIVGJR7HROBdYCewJ+A3xfEfT3Zd6dHimcOcAzQCpxPljSvSO//HmT/WfbMvTebkCXgTYE3gAMKv5u579Xx7cR/AvBPoHcu5l58nOTG5tZd6P1gwcS42L+1enjUPICKvRA4HHi9xDovAnvnpvcEXsp9WDPIJVay/822S8/PYdES47vAgUCPghiO5uPEeCQwomD5k8DRuS/wWbllXwfu6+C1tcXfmqZ7pXi2za0zqu3H0s72pwB/zk23lxhnAcsUzJtcsJ+hwD+AZ0klhDI+u3XT+9UCXAV8lY9LhkOAU9s7Hh0nxjVz80YAg8v4/Od/Lu29B5SfGHfMTd8KnJGeDyeVgtP0BmSlrrb/mIL0n1Yungm56U3SOqvm5r0FbN5BLJcClxR+N3Pfq+ML1t+R7Pu+fgf765P2sXxH7wcLJsbF/q3Vw6OZ2hjfAlYq0T6zOllVps3Lad78fcSCbYgfkv3vvkgiYjpZ9fNEYIqkeyR9uox42mJaIzf9+iLE81ZEzE3PZ6S/b+SWz2jbXtL6ku6W9Lqk/5K1y65UZN8AUyNiZol1fg1sDFweER+VWBeAiHiRrEq2ObATWanrNUkbALsAj5Szn5yO3rNSn38lLMqxu5C1hbd5pWBfhZ8dEdHR57mtpIckTZX0Htl3r9TnSdq2L1kSPyoi/pXmtUq6SNKL6fvxUlq9rH1Spd9aZ2mmxPgkWVXxgCLrvEbWidJmrTRvcUwnqzK2+WR+YUTcHxG7k1Wj/0mWMErF0xbTq4sZ06L4FVlc/SOiN/A9sna8YqLYQkk9yUoq1wLnSFpxEeJ5BDiIrJ3z1TT9P8AKZCMLFjmedhT7/Bf4PCUt8HkuxrHKOfYcFkx+S3KMG8lK630jYnmyknepzxNJPYA7gEsj4t7cosPIOi13I2u/79e2SZmxVvK3VnVNkxgj4j2y9rUrJB0gaVlJXSXtJenitNpNwFmSVpa0Ulr/hsU85FhgZ0lrSVoeOLNtgaRVJe0naTmyNq4PgLnt7OMvwPqSDpPURdIhwEZkJabO1ousHfSDVJr9WsHyN8jawxbFZcCoiDgeuIfsxwmApHMkPVxk20eAb5A18kNW3fsmWfW2vfducWIs9vk/AwyQtLmkZciaSpbkWO0d+38lrZ3+A/kxWTtqpUY59ALejoiZkrYhS2zluA74Z0RcXDC/F9l39y2y/zB+XLC81PtRyd9a1TVNYgSIiJ+TjWE8i6zh+xWyH9sdaZXzgZFk7V//AEaneYtzrAeAW9K+RrFgMmsh63F7jaxHdRey9sHCfbwF7JvWfYusZ3XfiJi2ODEtotPJfjzvk5VmbylYfg4wRNK7kr5cameS9ifrADsxzToV+Iykw9N0X7Je1o48QvZjbEuMj5P9IB/tcAu4kOzH966k00vFSJHPP1UhzwUeJOtVLhz3ei2wUTrWHWUcq9B1ZD3pj5KNUphJlvgr5evAuZLeJ0tCt5a53WDgi5I+yD12IusIepms9jKerCMlr9T7UbHfWi003QBvq0+SxgK7pv8MzOqaE6OZWYGmqkqbmVWCE6OZWQEnRjOzAj5ZfTGpS49Qt161DmOpsvmGa9U6hKXSmNGjpkXEypXYV2vvT0XMmVFyvZgx9f6IGFSJYy4OJ8bFpG696L5ByVEsVkFPPHV5rUNYKi3braXw7KzFFnNmlPW7mTn2inLPsOkUToxmVj0StLTWOoqSnBjNrLpU/10bToxmVl0qeQp3zTkxmlkVuSptZrYg4aq0mdmCXGI0M1uY2xjNzPLkqrSZ2QKEq9JmZgtyidHMbGEtbmM0M/uYq9JmZoVclTYzW5hLjGZmOZLHMZqZLcRVaTOzPJ8SaGa2MFelzcxyfHUdM7NCrkqbmS2sAUqM9R+hmTWXtiE7xR5l7UatksZIujtNryjpAUkT0t8VcuueKWmipBck7Vlq306MZlY9bXcJLPUoz7eA53PTZwDDI6I/MDxNI2kjYDAwABgEXCmp6EGcGM2sqiSVfJSxjzWBfYDf5GbvDwxJz4cAB+Tm3xwRH0XEJGAisE2x/TsxmlnVSKAWlXwAK0kamXucULCrS4HvAPNy81aNiCkA6e8qaf4awCu59SaneR1y54uZVVF5JUJgWkRs1e4epH2BNyNilKSBZR10YVFsAydGM6uqMhNjMZ8F9pO0N7AM0FvSDcAbklaLiCmSVgPeTOtPBvrmtl8TeK3YAVyVNrOqamlpKfkoJiLOjIg1I6IfWafKXyPiCGAocFRa7SjgzvR8KDBYUndJawP9gRHFjuESo5lVj2i/YlsZFwG3SjoO+A9wMEBEjJN0KzAemAOcFBFzi+3IidHMqkbltzGWJSIeBh5Oz98Cdu1gvQuAC8rdrxOjmVVVqapyPXBiNLOqqmSJsbM4MZpZ9aRxjPXOidHMqqbSbYydxYnRzKrKidHMLM9VaTOzhbnEaGZWoBESY/0PKLLF0tIinrzpu9x+2Ynz531t8C488+cfMOqP3+eCb+2/wPp9P7kCU5/4P045st3xsbaYZs6cyU47bMu2W27OlpttzHk/+mGtQ6opUfrKOvVQ1XaJsUl947DP8cKkN+i13DIA7LxVf/YduAlbf/lCZs2ew8or9Fxg/YtPP5BhT4yrRahNrXv37tw7bDg9e/Zk9uzZ7DpwJ/YctBfbbLtdrUOrDbnEaDWyxip9GLTjAH7757/Nn3fCwTvxs98+wKzZcwCY+s4H85d9YeCmTJo8jfEvvl71WJudJHr2zP4Tmj17NrNnz26I24d2pkpcqLazOTE2oZ9++0C+f9kdzJv38SXn1vvUKnx2i3V59PrTGfabb7HlRmsBsOwy3TjtmN254Oq/1Crcpjd37ly23WoLPrXGquy6625ss822tQ6pphqhKu3EmCOpn6TDah3Hkthrp4158+33GfP8KwvM79Lawgq9l2Xn//kZ37vkDm64+FgAfvC1fbj8hr8yfcasWoS7VGhtbeXvI8cwYdIrjBz5NOOee67WIdVUI5QYG6aNUVKXiJjTyYfpBxwG3NjJx+k022++DvvusgmDdhxA925d6b3cMlx3/v/w6hvvcsfwZwAYOe5l5s0LVlqhJ1tv/Cm+uNvmXHDKASzfqwfz5gUzZ83mqlserfEraT59+vRhp5134YFh9zFg441rHU5NSFq6LyIhqR9wL/A4sAPwKtlNaTYArgKWBV4Ejo2IdzrYx8PA38iu2Ds0Tf8c6AlMA45OV+t9GBhLdoOb3mmfIyQtB1wObEL2Ws+JiDtTbL8HlkuH+kZE/I3sem4bShoLDImISyrzblTP2ZcP5ezLhwKw05b9OeV/duXYs67n+IN2ZOA26/PYqAmst9YqdOvahWnvfMBux106f9vvf3Vvpn/4kZNiBU2dOpWuXbvSp08fZsyYwUN/Hc6pp3+n1mHVVD2UCEvp7BJjf+DQiPhKulDkgWQ3sPlmRDwi6Vzgh8ApRfbRJyJ2kdQVeATYPyKmSjqE7Ppqx6b1louIHSTtDFwHbAx8n+zqvsdK6gOMkPQg2SXPd4+ImZL6AzcBW5HdbvH0iNi3vUDSDXmym/J07dneKnVryB1PcvU5hzPytu8xa/Zcjj/797UOaanw+pQpfOW4o5k3dy7z5s3jSwcdzN77tPv1WnrUf17s9MQ4KSLGpuejgHXJEt0jad4Q4LYS+7gl/d2ALNk9kP7HaQWm5Na7CSAiHpXUOyXCPcjuDXF6WmcZYC2y+z38UtLmwFxg/XJeTERcA1wD0LLsKkVvplMPHhs1gcdGTQBg9py5HHvW9UXXdwdM5W2y6aY89fToWodRP+TrMQJ8lHs+F+izGPuYnv4KGBcR23ewXmGiirTNgRHxQn6BpHOAN4DNyDqgZi5GXGa2iERjjFaqdup+D3hH0k5p+kiy6nE5XgBWlrQ9gKSukgbklh+S5u8IvBcR7wH3A99UKmJK2iKtuzwwJSLmpRha0/z3gV6L9crMrAyle6TroQ2yFr3SRwFXSVoW+DdwTDkbRcQsSQcBv5C0PFnslwJtp2u8I+lvpM6XNO+8tM6zKTm+BOwLXAncLulg4CE+LpU+C8yR9Azwu0bsfDGrdy11ME6xlE5LjBHxElmbYNv0z3KLyzofKiIGFkyPBXbuYPXbI+LMgvVnAF9tZ78TgE1zs85M82fTwc10zKwC1BhV6YYZx2hmjU9Aa2v9Z8a6SIySriAbq5h3WUT8tpztC0uWZla/6qENsZS6SIwRcVKtYzCzKnBV2sxsQWIpPyXQzKw9LjGamRVwG6OZWY60lI9jNDNrTwMUGJ0Yzay6XGI0M8vzzbDMzBbUdnWdUo+i+5CWkTRC0jOSxkn6UZq/oqQHJE1If1fIbXOmpImSXpC0Z6k4nRjNrIpES0vpRwkfAZ+PiM2AzYFBkrYju9D08IjoDwxP00jaCBgMDAAGAVdKam1vx22cGM2sqpb0smORabv/b9f0CLJbpwxJ84cAB6Tn+wM3R8RHETEJmEh2G5QOOTGaWfWUUY1OeXElSSNzjxMW2I3Umu7N9CbwQET8HVg1IqYApL+rpNXXAPK3zZyc5nXInS9mVjWi7FsbTIuIrTpaGBFzgc3TLUz+LKnYbRfbK4IWvTWJS4xmVlVL2vmSFxHvAg+TtR2+IWm17Bhajaw0CVkJsW9uszXJ7vvUISdGM6uqJW1jlLRyKikiqQewG/BPYCjZHQJIf+9Mz4cCgyV1l7Q22d1LRxQ7hqvSZlY1Ulm9zqWsBgxJPcstwK0RcbekJ4FbJR0H/Ac4GCAixqXbN48H5gAnpap4h5wYzayqlnR8d0Q8C2zRzvy36ODWJBFxAdl96MvSYWKUdDlFGigj4uRyD2Jm1qa1wU8JHFm1KMxsqaAGOSWww8QYEUPy05KWi4jpHa1vZlaOBigwlu6VlrS9pPHA82l6M0lXdnpkZtaUKnBKYOfHWMY6lwJ7Am8BRMQzdHxvZzOzDonsvi+l/tVaWb3SEfFKQbtA0a5uM7OO1EGBsKRyEuMrknYAQlI34GRStdrMbJFUZhxjpysnMZ4IXEZ20vWrwP2A7wNtZotMQEsj90q3iYhpwOFViMXMlgKNUGIsp1d6HUl3SZoq6U1Jd0papxrBmVlzKecCEvVQoCynV/pG4Fay8xNXB24DburMoMysebVIJR+1Vk5iVET8PiLmpMcNlLiWmZlZRxohMRY7V3rF9PQhSWcAN5MlxEOAe6oQm5k1mazzpdZRlFas82UUWSJsexlfzS0L4LzOCsrMmlQZ11usB8XOlV67moGY2dKhEXqlyzrzJd1PYSNgmbZ5EXF9ZwVlZs2pGarSAEj6ITCQLDH+BdgLeBxwYjSzRVYPnSullNMrfRDZVXFfj4hjgM2A7p0alZk1JanBe6VzZkTEPElzJPUmu/OWB3ib2WKpg7xXUjmJcWS6I9evyXqqP6DEHbbMzDrSFJ0vEfH19PQqSfcBvdPNaMzMFomoj6pyKcUGeH+m2LKIGN05ITWGTTboy7BHLql1GEuVRhj/ZiXUybnQpRQrMf5fkWUBfL7CsZjZUqC1ATJjsQHen6tmIGbW/ERjlPzLGuBtZlYpDdD34sRoZtUjQWsDZEYnRjOrqgbIi2VdwVuSjpB0dppeS9I2nR+amTUbkZUYSz1qrZxTAq8EtgcOTdPvA1d0WkRm1tRaynjUWjlV6W0j4jOSxgBExDvpNqpmZousATqly0qMsyW1km5nIGllYF6nRmVmTUmqj6pyKeWUWn8B/BlYRdIFZJcc+3GnRmVmTatFpR+1VjIxRsQfgO8AFwJTgAMi4rbODszMmk92odolu+yYpL6SHpL0vKRxkr6V5q8o6QFJE9LfFXLbnClpoqQXJO1ZKs5yeqXXAj4E7gKGAtPTPDOzRSNobSn9KGEOcFpEbAhsB5wkaSPgDGB4RPQHhqdp0rLBwABgEHBlah7sUDltjPfw8U2xlgHWBl5IBzEzWyRiyerKETGFrPZKRLwv6XlgDWB/srsNAAwBHga+m+bfHBEfAZMkTQS2AZ7s6BjlXHZsk/x0uurOVztY3cysQwK6lDceZyVJI3PT10TENQvtT+oHbAH8HVg1JU0iYoqkVdJqawBP5TabnOZ1aJHPfImI0ZK2XtTtzMyg7ItITIuIrUrspydwO3BKRPy3yH7bWxDF9l3OzbBOzU22AJ8BppbazsysUKXuEiipK1lS/ENE/CnNfkPSaqm0uBrZbVggKyH2zW2+JvBasf2XU6jtlXt0J2tz3L/8l2BmlmjJTwlUVjS8Fng+In6eWzQUOCo9Pwq4Mzd/sKTuktYG+lPi9ixFS4yp56ZnRHy7aKRmZmWoUInxs8CRwD8kjU3zvgdcBNwq6TjgP8DBABExTtKtwHiyHu2TImJusQMUu7VBl4iYU+wWB2Zmi2pJTwmMiMdpv90Qsls9t7fNBcAF5R6jWIlxBFl74lhJQ4HbgOm5A/2pow3NzNoj1Ni3NshZEXiL7B4vbeMZA3BiNLNFUyen/JVSLDGuknqkn+PjhNimaFe3mVl72q7HWO+KJcZWoCeLMQbIzKwjDX1faWBKRJxbtUjMbKnQAHmxaGJsgPDNrJFIDX5faTro9jYzWxL1nxaLJMaIeLuagZhZ82u7HmO98+1TzayqGqBT2onRzKpJ5V5dp6acGM2sakR93B61FCdGM6sqtzGameWp7AvV1pQTo5lVjWj8cYxmZhVX/2nRidHMqqwBCoxOjGZWPa5Km5ktREt8X+lqcGI0s6pqgAKjE6OZVU+jXF2nEQah22KaOXMmgz63A5//7JbsvO1mXPzjHwHwk/N/yOd2+Ay77rgVhxywN69PKXqLXVtCw+6/j00HbMCAT6/HTy++qNbh1JxU+lFrToxNrHv37tx+1zD++sQohj8+koceHMaop//O108+jYf+Nprhj49k90F78/OflH3zNFtEc+fO5ZSTT+LOu+5lzLPjue3mm3h+/Phah1UzbZ0vpR615sTYxCSxXM+eAMyePZs5s2cjiV69e89f58Pp0+vjv+gm9fSIEay77nqsvc46dOvWjYMPGczdd91ZesMmpjL+1ZrbGJvc3Llz2WOXbZn07xc55vgT+cxW2wBw4bk/4Lab/0Cv3r25/e4Hahxl83rttVdZc82+86fXWGNNRoz4ew0jqr1G+H/YJcYcSQdI2qjWcVRSa2srwx8fyZjxkxgzeiTPj38OgDPPPo/R4//NgQcfynXXXFnjKJtXxML3jWuEc4U7i6vSFaZMZ8d7ANBUibHN8n36sMOOO/PQg8MWmP/Fgwdzz9A/1yiq5rfGGmsyefIr86dffXUyq6++eg0jqrVyKtJOjEVJ6ifpeUlXAqOBH0h6WtKzkn6UW+efkoak+X+UtGxatqWkRySNknS/pNXS/K+k/Twj6XZJy0raAdgP+KmksZLWrdXrrpRp06by3rvvAjBjxgwee/ivrLf+Bvz7xQnz17n/3rtZr/8GNYqw+W219dZMnDiBlyZNYtasWdx2y83ss+9+tQ6rdsroka6DAmNDtDFuABwD3AEcBGxDViIfKmln4D9pneMi4glJ1wFfl3QZcDmwf0RMlXQIcAFwLPCniPg1gKTz07aXSxoK3B0Rf6zuS+wcb74+hZNPPI658+Yyb9489vviQewxaB+OO+LLTJz4L1paWliz71pcfMkVtQ61aXXp0oVLLvslX9hnT+bOnctRRx/LRgMG1DqsmvEpgZXzckQ8JelnwB7AmDS/J9CfLDG+EhFPpPk3ACcD9wEbAw+kNp1WYEpaZ+OUEPuk/dxfTiCSTgBOAFiz71pL9qqqYKONN+XBx59eaP61N9xag2iWXoP22ptBe+1d6zDqRv2nxcZIjNPTXwEXRsTV+YWS+gGFLdyR1h8XEdu3s8/fAQdExDOSjgYGlhNIRFwDXAOw2RZbLtyqbmalNUBmrOs2xgL3A8dK6gkgaQ1Jq6Rla0lqS4CHAo8DLwArt82X1FVSWx2mFzBFUlfg8Nwx3k/LzKyTtEglH7XWMIkxIoYBNwJPSvoH8Ec+TmLPA0dJehZYEfhVRMwia5P8iaRngLHADmn9HwB/Bx4A/pk7zM3AtyWNaYbOF7N6pDIeJfchXSfpTUnP5eatKOkBSRPS3xVyy86UNFHSC5L2LLX/uq5KR8RLZO2EbdOXAZfl10lV6XkRcWI7248Fdm5n/q+AX7Uz/wmadLiOWT0QFRvH+Tvgl8D1uXlnAMMj4iJJZ6Tp76axyYOBAcDqwIOS1o+IuR3tvGFKjGbWBCo0XCciHgXeLpi9PzAkPR9CNi65bf7NEfFRREwCJpKNbulQwyfGiHgpIjYuvaaZ1YMyq9IrSRqZe5xQxq5XjYgpAOlvWx/EGsArufUmp3kdquuqtJk1G5VblZ4WEVtV7KALKzqqpOFLjGbWWDrxzJc3cme3rQa8meZPBvrm1lsTKHoRUidGM6uacqrRS9A1MxQ4Kj0/CrgzN3+wpO6S1iY7MWREsR25Km1mVVWJXmlJN5GdmLGSpMnAD4GLgFslHUd2RtzBABExTtKtwHhgDnBSsR5pcGI0syqrxGidiDi0g0W7drD+BWTXSiiLE6OZVU+dXD2nFCdGM6uqerjeYilOjGZWNdmZL7WOojQnRjOrKidGM7MCrkqbmRVwidHMrIATo5lZTnZmS/1nRidGM6seQUv950UnRjOrMidGM7M8uSptZpYnXJU2M1uYE6OZ2YJclTYzK+CqtJlZni87ZmbWnvrPjE6MZlY17pU2M2uHq9JmZgUqcTOszubEaGZVVf9p0YnRzKpI7pU2M1uYq9JmZgXqPy06MZpZlTVAgdGJ0cyqR4iWBsiMLbUOwMys3rjEaGZV1QglRidGM6seD9cxM1uQcK+0mdlCGmEcoztfzKyq2s5+KfYovQ8NkvSCpImSzqh0jE6MZlZVKuNRdHupFbgC2AvYCDhU0kaVjNGJ0cyqSlLJRwnbABMj4t8RMQu4Gdi/kjG6jXExPTt29LRPLt/t5VrHsZhWAqbVOoilTCO/55+q1I7GjB51/7LdtFIZqy4jaWRu+pqIuCY9XwN4JbdsMrBtpWIEJ8bFFhEr1zqGxSVpZERsVes4liZ+zzMRMagCu2mvSBkV2O98rkqbWaOZDPTNTa8JvFbJAzgxmlmjeRroL2ltSd2AwcDQSh7AVeml0zWlV7EK83teIRExR9I3gPuBVuC6iBhXyWMooqJVczOzhueqtJlZASdGM7MCToxmZgWcGM3MCjgxWlGSllc6R0vSNrWOp5kos1p6vpakrrWOyTIermMdktQF+Dywp6QewIuSng4PZaiUrYHtJXUHjgZ2BabUNCIDPFzHSpC0OvAQ0BXYIiLek9Q1ImbXOLSmIOkm4AvAdyPiilrHYxlXpW0hWvDyJm8CfwDuAH4uaTUnxYr6Hdn7u6akndOZHEjyb7OGXGK0BUhSW1VZ0u7AWxExWlIv4AJgeeAYsqrfxIh4tGbBNqC291fS1mRnbUyNiBclnQt8Argq/e0HDHGzRW04MVq7JF0LdAd6AHMi4hBJnwB+COwBvATsExFzaxdlY5K0H/AjYBiwLnA9cDdwDvBJYD/ghIio6Pm/Vj4nRluIpLOAdSPiGEm3AZ8DxkXELmn5QOCxiJgrqSUi5tUu2sYiaQPgV8ChZBdXPRl4DvhjRPxRUl9guYj4Z770btXlxGgU/gAlbUhWIrwEeDcizpD0CvBqRGyXW6/VJcZFI6kf0BtYAbgUOBI4iKyUeHVEXF2z4Gw+N/Au5QraFNeV9KmIeJ7swp89gFvSqjcAr+Y7BZwUS8uNAd1Q0ieBmRHxLLA+8KuIeA6YADwJPFW7SC3P4xiXcrmk+AdgJrCzpMvJEuH7wJckfQ94CzgodRy4+lym9H7tDZwP3A7sI+kwYDrwmzSo+2Tg2Ih4poahWo5LjIak75JVmY8D3gZWiIi3yYaSvAy8Dnwj/cjlpFg+SWuTdarsD/yX7LL8/42IG4FjgZWBb0XEEzUL0hbiNkZD0hHAu8BhwDsRcZKkVYGeEfFibj23KZYpNyxnLbIEOAr4PnBEREyUtCvwt4iYkV+/hiFbjkuMS5mCwdvzZ5N1tLwcESeleecDp+e3cVIsLff+9kh/XwN2JxuSs3tKijsB3wNWadvOSbG+uMS4FCnoaLkKmEfWzvwtsiEkc4ERwOZk4+v2jog5tYm2cUkaBHyTbBjOM8DzZNXpCcAYsv9wzomIO2sVoxXnEuNSJJcUvwasCPySbEDxEOAbZD2jK5Ld/3jvdG+N1hqF25AkbQl8Dfg9Wfvs7mTDcU4CliO7R/MZEXFnB6V3qwMuMS5lJJ0JDAQujIiH07zbgQ8j4siCdd2muAhSe+LDwC0Rcaak5ciG5ZxOlgxfKba91Q+XGJtcO6WSsWTnO+8oqXeadyIwL11mbD4nxUUTEf8hG/d5gqT1ImJ6RIwBliFrmrAG4XGMTaygTfFYYBIwHvg68HPgv5KeAL4MrErWxmhlKrggxHpk7Ynnk/Xw3yHpZLLrKw4gG7doDcIlxiaWS4q/AXYDtgfuAv4B/JTsfN0fAB+QtSmG273Kl96vLwC/BTYgu3zYfhHxE7IbwP+FrPf5yxHxtN/bxuHE2ITyP0BJOwKzIuIwsitG3xcRsyPiHuDbQB+yy4fNS2e0uNG5TJI+DexJdpXzR8l+T8PT4u8D3wH6A1NrEqAtNne+NDFJB6annwd6AW9HxClp2TER8VtJ+wIXkl3m6snaRNo4ctXnbciGOD1F1oa4EXBoRLyUTgH8VxqzeAFZSX0QMNv/8TQGJ8YmJek0YDXgTFJpJiK2Tct+QXYq2uGppLh5RIytWbANJiXFs4FfkF0p5yzg9Ih4UNL2ZMOfjoiIEWn9T0TEWzUL2BaZE2MTSuc+bwr8PCJGpR/yeWRtie8DKwEHpHGK+Q4an5ZWBkl7APcCpwDXAj8jG//5IbAd8J2IuLtmAdoSc690c3oX+DSwpaSxETFC0peAL6Vl97YN3s4PyXFSLE9EDEvNFBcDL5AN3t4K6AtcHhFj/J9MY3NibEIRcbWkmcARwEuSHomI6WRnYwAevL2kIuIOSXOAi4CV0tVyns4td1JsYE6MTaatpBIRQ9K1/k4Dukv6S0Hp0ElxCUXE3emUyQslPQy87kuyNQe3MTaBdm5NkG83/BawdltvtFWepJUjwkNymogTYwPqKBHmr6ztThWzxefE2MDSGLluwEfAtRExqSA5zm9H9JARs/L5zJcGJelqsiu3PEV2odk/SlqnoMTYlhQPBb4mqXvNAjZrIO58aRDtVIe7AV+N7N4st0v6CDhF0qlknaL5pHgGMDgiPqp64GYNyCXGBlDQXriDpFXIBnDnr5/4GFnTyJxcUjwCOJXsVLXnqx23WaNyibHOFSTFXwM7k125ZTjwbUkzI7tJ+95k11ls225r4Bjg6IgYX/3IzRqXO18ahKTTya6E8wPgOLJznfsDu5CdnrY+uXu0SOoBLB8Rr9ckYLMG5sTYACRtSNbJcl1E/G/qRDmQ7BS03mQXnX07DdlpJWtj9EBjs8XkNsYGkNoHjwK+KOmQ1IlyM9lNq97k46SoiJjrpGi2ZNzG2CDSubmzgB+nsYo3SbrOg7jNKs+JsYFExF8kBfBbSdMi4oHcMidFswpxG2MDShdDHeELQZh1DifGBuZLh5l1DidGM7MC7pU2MyvgxGhmVsCJ0cysgBOjmVkBJ0brkKS5ksZKek7SbZKWXYJ9/U7SQen5byRtVGTdgZJ2WIxjvCRppXLnF6zzwSIe65x0/ro1ISdGK2ZGRGweERsDs4AT8wvTedmLLCKOL3HFn4HAIidGs0pxYrRyPQasl0pzD0m6EfiHpFZJP5X0tKRnJX0VslMUJf1S0nhJ9wCrtO1I0sOStkrPB0kaLekZScMl9SNLwP+bSqs7SVpZ0u3pGE9L+mza9hOShkkak65orlIvQtIdkkZJGifphIJl/5diGS5p5TRvXUn3pW0ek/TpirybVtd8SqCVJKkLsBdwX5q1DbBxusfMCcB7EbF1uurPE5KGAVsAGwCbAKsC44HrCva7MvBrYOe0rxUj4m1JVwEfRMTP0no3ApdExOOS1gLuBzYEfgg8HhHnStoHWCDRdeDYdIwewNOSbk/3wlkOGB0Rp0k6O+37G8A1wIkRMUHStsCVwOcX4220BuLEaMX0kDQ2PX8MuJasijsiIial+XsAm7a1H5JdLLc/2QV1b0pn5rwm6a/t7H874NG2faXbNLRnN2AjaX6BsLekXukYX0rb3iPpnTJe08mSvpie902xvgXMA25J828A/iSpZ3q9t+WO7fvmLAWcGK2YGRGxeX5GShDT87OAb0bE/QXr7Q2UOq1KZawDWZPP9hExo51Yyj51S9JAsiS7fUR8KOlhYJkOVo903HcL3wNrfm5jtCV1P9kdCLsCSFpf0nLAo8Dg1Aa5GvC5drZ9EthF0tpp2xXT/PeBXrn1hpFVa0nrbZ6ePgocnubtBaxQItblgXdSUvw0WYm1TQvQVuo9jKyK/l9gkqSD0zEkabMSx7Am4MRoS+o3ZO2HoyU9B1xNVhP5MzAB+AfwK+CRwg0jYipZu+CfJD3Dx1XZu8guyjtW0k7AycBWqXNnPB/3jv8I2FnSaLIq/X9KxHof0EXSs8B5ZFdFbzMdGCBpFFkb4rlp/uHAcSm+ccD+Zbwn1uB8EQkzswIuMZqZFXBiNDMr4MRoZlbAidHMrIATo5lZASdGM7MCToxmZgX+H5+1YM8q+wUJAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 混淆矩阵可视化\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class_names = ['no_repeat', 'repeat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train,\n",
    "                                                    target,\n",
    "                                                    random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = \".2f\" if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i,\n",
    "                 format(cm[i, j], fmt),\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      classes=class_names,\n",
    "                      normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.926"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同的分类模型\n",
    "# 逻辑回归\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.93"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同的分类模型\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0.424"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 不同的分类模型\n",
    "# 高斯贝叶斯\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.872"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同的分类模型\n",
    "# 决策树\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "0.934"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同的分类模型\n",
    "# Bagging based on KNN\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.924"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同的分类模型\n",
    "# 随机森林\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "0.92"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同的分类模型\n",
    "# 极端森林\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0.934"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同的分类模型\n",
    "# Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=10)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "0.926"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同的分类模型\n",
    "# GBDT\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=10, max_depth=1, learning_rate=1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93 (+/- 0.01) [LogisticRegression]\n",
      "Accuracy: 0.93 (+/- 0.00) [Random Forest]\n",
      "Accuracy: 0.46 (+/- 0.01) [naive Bayes]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93 (+/- 0.01) [Ensemble]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# 集成学习\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "y = target\n",
    "\n",
    "clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), (\"rf\", clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], [\"LogisticRegression\", \"Random Forest\", \"naive Bayes\", \"Ensemble\"]):\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6016\n",
      "[LightGBM] [Info] Number of data points in the train set: 1200, number of used features: 122\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score -0.060989\n",
      "[LightGBM] [Info] Start training from score -2.827397\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 0.317017\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's multi_logloss: 0.317322\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's multi_logloss: 0.317318\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's multi_logloss: 0.317723\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's multi_logloss: 0.318098\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's multi_logloss: 0.318218\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's multi_logloss: 0.318611\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's multi_logloss: 0.31899\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's multi_logloss: 0.319151\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's multi_logloss: 0.319348\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's multi_logloss: 0.319347\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's multi_logloss: 0.319438\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's multi_logloss: 0.319636\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's multi_logloss: 0.320033\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's multi_logloss: 0.320222\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's multi_logloss: 0.320487\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's multi_logloss: 0.320836\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's multi_logloss: 0.321198\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's multi_logloss: 0.321528\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's multi_logloss: 0.321691\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's multi_logloss: 0.32196\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's multi_logloss: 0.322356\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's multi_logloss: 0.322394\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's multi_logloss: 0.32267\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's multi_logloss: 0.323041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's multi_logloss: 0.323409\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's multi_logloss: 0.323495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's multi_logloss: 0.323774\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's multi_logloss: 0.323728\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's multi_logloss: 0.323577\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's multi_logloss: 0.323458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's multi_logloss: 0.323736\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's multi_logloss: 0.323876\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's multi_logloss: 0.32439\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's multi_logloss: 0.324352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's multi_logloss: 0.324518\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's multi_logloss: 0.324478\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's multi_logloss: 0.324901\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's multi_logloss: 0.324784\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's multi_logloss: 0.325209\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's multi_logloss: 0.325396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's multi_logloss: 0.325153\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's multi_logloss: 0.325346\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's multi_logloss: 0.325777\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's multi_logloss: 0.326282\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's multi_logloss: 0.326542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's multi_logloss: 0.326603\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's multi_logloss: 0.327063\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's multi_logloss: 0.327568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.327874\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's multi_logloss: 0.327947\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's multi_logloss: 0.328139\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's multi_logloss: 0.328532\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's multi_logloss: 0.328786\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's multi_logloss: 0.328872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[56]\tvalid_0's multi_logloss: 0.329141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\tvalid_0's multi_logloss: 0.329131\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's multi_logloss: 0.329436\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[59]\tvalid_0's multi_logloss: 0.329829\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.329947\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[61]\tvalid_0's multi_logloss: 0.3302\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[62]\tvalid_0's multi_logloss: 0.330311\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[63]\tvalid_0's multi_logloss: 0.330257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[64]\tvalid_0's multi_logloss: 0.330383\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[65]\tvalid_0's multi_logloss: 0.330721\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\tvalid_0's multi_logloss: 0.330917\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\tvalid_0's multi_logloss: 0.331154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tvalid_0's multi_logloss: 0.331287\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[69]\tvalid_0's multi_logloss: 0.331844\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's multi_logloss: 0.332026\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\tvalid_0's multi_logloss: 0.332339\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[72]\tvalid_0's multi_logloss: 0.332373\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[73]\tvalid_0's multi_logloss: 0.332751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\tvalid_0's multi_logloss: 0.333049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\tvalid_0's multi_logloss: 0.33316\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[76]\tvalid_0's multi_logloss: 0.33342\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[77]\tvalid_0's multi_logloss: 0.333668\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[78]\tvalid_0's multi_logloss: 0.333723\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[79]\tvalid_0's multi_logloss: 0.333966\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's multi_logloss: 0.334203\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[81]\tvalid_0's multi_logloss: 0.334147\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[82]\tvalid_0's multi_logloss: 0.334289\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[83]\tvalid_0's multi_logloss: 0.334722\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[84]\tvalid_0's multi_logloss: 0.334988\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[85]\tvalid_0's multi_logloss: 0.335199\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[86]\tvalid_0's multi_logloss: 0.335562\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[87]\tvalid_0's multi_logloss: 0.335723\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[88]\tvalid_0's multi_logloss: 0.335857\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[89]\tvalid_0's multi_logloss: 0.33611\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\tvalid_0's multi_logloss: 0.336275\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[91]\tvalid_0's multi_logloss: 0.33664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[92]\tvalid_0's multi_logloss: 0.337008\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[93]\tvalid_0's multi_logloss: 0.337328\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[94]\tvalid_0's multi_logloss: 0.337618\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[95]\tvalid_0's multi_logloss: 0.338001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[96]\tvalid_0's multi_logloss: 0.338188\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[97]\tvalid_0's multi_logloss: 0.338504\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[98]\tvalid_0's multi_logloss: 0.338815\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[99]\tvalid_0's multi_logloss: 0.338874\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.339034\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[101]\tvalid_0's multi_logloss: 0.339364\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 0.317017\n",
      "score:  0.9475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\InstallSoft\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "clf = lightgbm\n",
    "train_matrix = clf.Dataset(X_train, label=y_train)\n",
    "test_matrix = clf.Dataset(X_test, label=y_test)\n",
    "params = {\n",
    "    'boosting_type': \"gbdt\",\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"min_child_weight\": 1.5,\n",
    "    \"num_leaves\": 2**5,\n",
    "    \"lambda_l2\": 10,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"colsample_bylevel\": 0.7,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"tree_method\": \"exact\",\n",
    "    \"seed\": 2017,\n",
    "    \"num_class\": 2,\n",
    "    \"silent\": True\n",
    "}\n",
    "\n",
    "num_round = 10000\n",
    "early_stopping_rounds = 100\n",
    "model = clf.train(params, train_matrix, num_round, valid_sets=test_matrix,early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "pre = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "print(\"score: \", np.mean((pre[:, 1]>0.5)==y_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.67042\teval-mlogloss:0.67256\n",
      "[1]\ttrain-mlogloss:0.64903\teval-mlogloss:0.65327\n",
      "[2]\ttrain-mlogloss:0.62886\teval-mlogloss:0.63508\n",
      "[3]\ttrain-mlogloss:0.60968\teval-mlogloss:0.61801\n",
      "[4]\ttrain-mlogloss:0.59154\teval-mlogloss:0.60201\n",
      "[5]\ttrain-mlogloss:0.57448\teval-mlogloss:0.58678\n",
      "[6]\ttrain-mlogloss:0.55833\teval-mlogloss:0.57224\n",
      "[7]\ttrain-mlogloss:0.54294\teval-mlogloss:0.55847\n",
      "[8]\ttrain-mlogloss:0.52843\teval-mlogloss:0.54546\n",
      "[9]\ttrain-mlogloss:0.51440\teval-mlogloss:0.53335\n",
      "[10]\ttrain-mlogloss:0.50108\teval-mlogloss:0.52186\n",
      "[11]\ttrain-mlogloss:0.48822\teval-mlogloss:0.51080\n",
      "[12]\ttrain-mlogloss:0.47621\teval-mlogloss:0.50038\n",
      "[13]\ttrain-mlogloss:0.46477\teval-mlogloss:0.49041\n",
      "[14]\ttrain-mlogloss:0.45372\teval-mlogloss:0.48111\n",
      "[15]\ttrain-mlogloss:0.44329\teval-mlogloss:0.47243\n",
      "[16]\ttrain-mlogloss:0.43316\teval-mlogloss:0.46389\n",
      "[17]\ttrain-mlogloss:0.42346\teval-mlogloss:0.45569\n",
      "[18]\ttrain-mlogloss:0.41441\teval-mlogloss:0.44818\n",
      "[19]\ttrain-mlogloss:0.40549\teval-mlogloss:0.44089\n",
      "[20]\ttrain-mlogloss:0.39700\teval-mlogloss:0.43373\n",
      "[21]\ttrain-mlogloss:0.38895\teval-mlogloss:0.42715\n",
      "[22]\ttrain-mlogloss:0.38120\teval-mlogloss:0.42100\n",
      "[23]\ttrain-mlogloss:0.37383\teval-mlogloss:0.41514\n",
      "[24]\ttrain-mlogloss:0.36671\teval-mlogloss:0.40939\n",
      "[25]\ttrain-mlogloss:0.35977\teval-mlogloss:0.40382\n",
      "[26]\ttrain-mlogloss:0.35337\teval-mlogloss:0.39868\n",
      "[27]\ttrain-mlogloss:0.34710\teval-mlogloss:0.39382\n",
      "[28]\ttrain-mlogloss:0.34092\teval-mlogloss:0.38905\n",
      "[29]\ttrain-mlogloss:0.33513\teval-mlogloss:0.38474\n",
      "[30]\ttrain-mlogloss:0.32951\teval-mlogloss:0.38053\n",
      "[31]\ttrain-mlogloss:0.32416\teval-mlogloss:0.37635\n",
      "[32]\ttrain-mlogloss:0.31912\teval-mlogloss:0.37262\n",
      "[33]\ttrain-mlogloss:0.31427\teval-mlogloss:0.36911\n",
      "[34]\ttrain-mlogloss:0.30951\teval-mlogloss:0.36564\n",
      "[35]\ttrain-mlogloss:0.30498\teval-mlogloss:0.36251\n",
      "[36]\ttrain-mlogloss:0.30045\teval-mlogloss:0.35945\n",
      "[37]\ttrain-mlogloss:0.29619\teval-mlogloss:0.35630\n",
      "[38]\ttrain-mlogloss:0.29218\teval-mlogloss:0.35349\n",
      "[39]\ttrain-mlogloss:0.28823\teval-mlogloss:0.35090\n",
      "[40]\ttrain-mlogloss:0.28447\teval-mlogloss:0.34842\n",
      "[41]\ttrain-mlogloss:0.28074\teval-mlogloss:0.34605\n",
      "[42]\ttrain-mlogloss:0.27729\teval-mlogloss:0.34386\n",
      "[43]\ttrain-mlogloss:0.27400\teval-mlogloss:0.34179\n",
      "[44]\ttrain-mlogloss:0.27076\teval-mlogloss:0.33959\n",
      "[45]\ttrain-mlogloss:0.26778\teval-mlogloss:0.33779\n",
      "[46]\ttrain-mlogloss:0.26490\teval-mlogloss:0.33610\n",
      "[47]\ttrain-mlogloss:0.26189\teval-mlogloss:0.33428\n",
      "[48]\ttrain-mlogloss:0.25912\teval-mlogloss:0.33268\n",
      "[49]\ttrain-mlogloss:0.25638\teval-mlogloss:0.33112\n",
      "[50]\ttrain-mlogloss:0.25378\teval-mlogloss:0.32970\n",
      "[51]\ttrain-mlogloss:0.25128\teval-mlogloss:0.32839\n",
      "[52]\ttrain-mlogloss:0.24893\teval-mlogloss:0.32710\n",
      "[53]\ttrain-mlogloss:0.24653\teval-mlogloss:0.32581\n",
      "[54]\ttrain-mlogloss:0.24427\teval-mlogloss:0.32470\n",
      "[55]\ttrain-mlogloss:0.24216\teval-mlogloss:0.32344\n",
      "[56]\ttrain-mlogloss:0.24013\teval-mlogloss:0.32253\n",
      "[57]\ttrain-mlogloss:0.23816\teval-mlogloss:0.32158\n",
      "[58]\ttrain-mlogloss:0.23625\teval-mlogloss:0.32083\n",
      "[59]\ttrain-mlogloss:0.23432\teval-mlogloss:0.32001\n",
      "[60]\ttrain-mlogloss:0.23259\teval-mlogloss:0.31918\n",
      "[61]\ttrain-mlogloss:0.23083\teval-mlogloss:0.31852\n",
      "[62]\ttrain-mlogloss:0.22900\teval-mlogloss:0.31786\n",
      "[63]\ttrain-mlogloss:0.22724\teval-mlogloss:0.31728\n",
      "[64]\ttrain-mlogloss:0.22554\teval-mlogloss:0.31679\n",
      "[65]\ttrain-mlogloss:0.22396\teval-mlogloss:0.31619\n",
      "[66]\ttrain-mlogloss:0.22240\teval-mlogloss:0.31568\n",
      "[67]\ttrain-mlogloss:0.22088\teval-mlogloss:0.31520\n",
      "[68]\ttrain-mlogloss:0.21921\teval-mlogloss:0.31450\n",
      "[69]\ttrain-mlogloss:0.21786\teval-mlogloss:0.31414\n",
      "[70]\ttrain-mlogloss:0.21662\teval-mlogloss:0.31383\n",
      "[71]\ttrain-mlogloss:0.21522\teval-mlogloss:0.31333\n",
      "[72]\ttrain-mlogloss:0.21402\teval-mlogloss:0.31309\n",
      "[73]\ttrain-mlogloss:0.21291\teval-mlogloss:0.31290\n",
      "[74]\ttrain-mlogloss:0.21161\teval-mlogloss:0.31265\n",
      "[75]\ttrain-mlogloss:0.21034\teval-mlogloss:0.31230\n",
      "[76]\ttrain-mlogloss:0.20915\teval-mlogloss:0.31218\n",
      "[77]\ttrain-mlogloss:0.20785\teval-mlogloss:0.31183\n",
      "[78]\ttrain-mlogloss:0.20671\teval-mlogloss:0.31156\n",
      "[79]\ttrain-mlogloss:0.20557\teval-mlogloss:0.31134\n",
      "[80]\ttrain-mlogloss:0.20425\teval-mlogloss:0.31122\n",
      "[81]\ttrain-mlogloss:0.20310\teval-mlogloss:0.31111\n",
      "[82]\ttrain-mlogloss:0.20211\teval-mlogloss:0.31104\n",
      "[83]\ttrain-mlogloss:0.20114\teval-mlogloss:0.31099\n",
      "[84]\ttrain-mlogloss:0.20007\teval-mlogloss:0.31103\n",
      "[85]\ttrain-mlogloss:0.19874\teval-mlogloss:0.31110\n",
      "[86]\ttrain-mlogloss:0.19765\teval-mlogloss:0.31122\n",
      "[87]\ttrain-mlogloss:0.19666\teval-mlogloss:0.31118\n",
      "[88]\ttrain-mlogloss:0.19578\teval-mlogloss:0.31134\n",
      "[89]\ttrain-mlogloss:0.19482\teval-mlogloss:0.31131\n",
      "[90]\ttrain-mlogloss:0.19391\teval-mlogloss:0.31138\n",
      "[91]\ttrain-mlogloss:0.19310\teval-mlogloss:0.31142\n",
      "[92]\ttrain-mlogloss:0.19237\teval-mlogloss:0.31157\n",
      "[93]\ttrain-mlogloss:0.19149\teval-mlogloss:0.31164\n",
      "[94]\ttrain-mlogloss:0.19061\teval-mlogloss:0.31171\n",
      "[95]\ttrain-mlogloss:0.18995\teval-mlogloss:0.31181\n",
      "[96]\ttrain-mlogloss:0.18911\teval-mlogloss:0.31212\n",
      "[97]\ttrain-mlogloss:0.18819\teval-mlogloss:0.31232\n",
      "[98]\ttrain-mlogloss:0.18740\teval-mlogloss:0.31254\n",
      "[99]\ttrain-mlogloss:0.18648\teval-mlogloss:0.31253\n",
      "[100]\ttrain-mlogloss:0.18540\teval-mlogloss:0.31270\n",
      "[101]\ttrain-mlogloss:0.18453\teval-mlogloss:0.31288\n",
      "[102]\ttrain-mlogloss:0.18373\teval-mlogloss:0.31299\n",
      "[103]\ttrain-mlogloss:0.18304\teval-mlogloss:0.31321\n",
      "[104]\ttrain-mlogloss:0.18232\teval-mlogloss:0.31337\n",
      "[105]\ttrain-mlogloss:0.18132\teval-mlogloss:0.31340\n",
      "[106]\ttrain-mlogloss:0.18068\teval-mlogloss:0.31375\n",
      "[107]\ttrain-mlogloss:0.17998\teval-mlogloss:0.31394\n",
      "[108]\ttrain-mlogloss:0.17907\teval-mlogloss:0.31416\n",
      "[109]\ttrain-mlogloss:0.17832\teval-mlogloss:0.31436\n",
      "[110]\ttrain-mlogloss:0.17759\teval-mlogloss:0.31457\n",
      "[111]\ttrain-mlogloss:0.17689\teval-mlogloss:0.31477\n",
      "[112]\ttrain-mlogloss:0.17602\teval-mlogloss:0.31495\n",
      "[113]\ttrain-mlogloss:0.17537\teval-mlogloss:0.31533\n",
      "[114]\ttrain-mlogloss:0.17475\teval-mlogloss:0.31557\n",
      "[115]\ttrain-mlogloss:0.17431\teval-mlogloss:0.31593\n",
      "[116]\ttrain-mlogloss:0.17352\teval-mlogloss:0.31609\n",
      "[117]\ttrain-mlogloss:0.17272\teval-mlogloss:0.31630\n",
      "[118]\ttrain-mlogloss:0.17196\teval-mlogloss:0.31650\n",
      "[119]\ttrain-mlogloss:0.17127\teval-mlogloss:0.31674\n",
      "[120]\ttrain-mlogloss:0.17057\teval-mlogloss:0.31697\n",
      "[121]\ttrain-mlogloss:0.16985\teval-mlogloss:0.31715\n",
      "[122]\ttrain-mlogloss:0.16911\teval-mlogloss:0.31742\n",
      "[123]\ttrain-mlogloss:0.16844\teval-mlogloss:0.31783\n",
      "[124]\ttrain-mlogloss:0.16776\teval-mlogloss:0.31817\n",
      "[125]\ttrain-mlogloss:0.16710\teval-mlogloss:0.31842\n",
      "[126]\ttrain-mlogloss:0.16633\teval-mlogloss:0.31876\n",
      "[127]\ttrain-mlogloss:0.16571\teval-mlogloss:0.31890\n",
      "[128]\ttrain-mlogloss:0.16513\teval-mlogloss:0.31918\n",
      "[129]\ttrain-mlogloss:0.16450\teval-mlogloss:0.31935\n",
      "[130]\ttrain-mlogloss:0.16391\teval-mlogloss:0.31942\n",
      "[131]\ttrain-mlogloss:0.16332\teval-mlogloss:0.31994\n",
      "[132]\ttrain-mlogloss:0.16264\teval-mlogloss:0.32019\n",
      "[133]\ttrain-mlogloss:0.16201\teval-mlogloss:0.32057\n",
      "[134]\ttrain-mlogloss:0.16145\teval-mlogloss:0.32083\n",
      "[135]\ttrain-mlogloss:0.16082\teval-mlogloss:0.32104\n",
      "[136]\ttrain-mlogloss:0.16003\teval-mlogloss:0.32115\n",
      "[137]\ttrain-mlogloss:0.15953\teval-mlogloss:0.32145\n",
      "[138]\ttrain-mlogloss:0.15877\teval-mlogloss:0.32144\n",
      "[139]\ttrain-mlogloss:0.15818\teval-mlogloss:0.32167\n",
      "[140]\ttrain-mlogloss:0.15762\teval-mlogloss:0.32200\n",
      "[141]\ttrain-mlogloss:0.15695\teval-mlogloss:0.32225\n",
      "[142]\ttrain-mlogloss:0.15645\teval-mlogloss:0.32251\n",
      "[143]\ttrain-mlogloss:0.15579\teval-mlogloss:0.32260\n",
      "[144]\ttrain-mlogloss:0.15517\teval-mlogloss:0.32283\n",
      "[145]\ttrain-mlogloss:0.15463\teval-mlogloss:0.32329\n",
      "[146]\ttrain-mlogloss:0.15419\teval-mlogloss:0.32358\n",
      "[147]\ttrain-mlogloss:0.15368\teval-mlogloss:0.32380\n",
      "[148]\ttrain-mlogloss:0.15304\teval-mlogloss:0.32403\n",
      "[149]\ttrain-mlogloss:0.15253\teval-mlogloss:0.32424\n",
      "[150]\ttrain-mlogloss:0.15201\teval-mlogloss:0.32451\n",
      "[151]\ttrain-mlogloss:0.15135\teval-mlogloss:0.32450\n",
      "[152]\ttrain-mlogloss:0.15069\teval-mlogloss:0.32457\n",
      "[153]\ttrain-mlogloss:0.15018\teval-mlogloss:0.32492\n",
      "[154]\ttrain-mlogloss:0.14969\teval-mlogloss:0.32506\n",
      "[155]\ttrain-mlogloss:0.14922\teval-mlogloss:0.32526\n",
      "[156]\ttrain-mlogloss:0.14870\teval-mlogloss:0.32560\n",
      "[157]\ttrain-mlogloss:0.14826\teval-mlogloss:0.32573\n",
      "[158]\ttrain-mlogloss:0.14766\teval-mlogloss:0.32572\n",
      "[159]\ttrain-mlogloss:0.14711\teval-mlogloss:0.32589\n",
      "[160]\ttrain-mlogloss:0.14652\teval-mlogloss:0.32607\n",
      "[161]\ttrain-mlogloss:0.14603\teval-mlogloss:0.32637\n",
      "[162]\ttrain-mlogloss:0.14551\teval-mlogloss:0.32651\n",
      "[163]\ttrain-mlogloss:0.14506\teval-mlogloss:0.32684\n",
      "[164]\ttrain-mlogloss:0.14448\teval-mlogloss:0.32687\n",
      "[165]\ttrain-mlogloss:0.14394\teval-mlogloss:0.32706\n",
      "[166]\ttrain-mlogloss:0.14347\teval-mlogloss:0.32721\n",
      "[167]\ttrain-mlogloss:0.14308\teval-mlogloss:0.32766\n",
      "[168]\ttrain-mlogloss:0.14263\teval-mlogloss:0.32810\n",
      "[169]\ttrain-mlogloss:0.14209\teval-mlogloss:0.32817\n",
      "[170]\ttrain-mlogloss:0.14160\teval-mlogloss:0.32826\n",
      "[171]\ttrain-mlogloss:0.14113\teval-mlogloss:0.32868\n",
      "[172]\ttrain-mlogloss:0.14072\teval-mlogloss:0.32893\n",
      "[173]\ttrain-mlogloss:0.14019\teval-mlogloss:0.32907\n",
      "[174]\ttrain-mlogloss:0.13974\teval-mlogloss:0.32932\n",
      "[175]\ttrain-mlogloss:0.13920\teval-mlogloss:0.32972\n",
      "[176]\ttrain-mlogloss:0.13874\teval-mlogloss:0.33006\n",
      "[177]\ttrain-mlogloss:0.13816\teval-mlogloss:0.33030\n",
      "[178]\ttrain-mlogloss:0.13763\teval-mlogloss:0.33031\n",
      "[179]\ttrain-mlogloss:0.13726\teval-mlogloss:0.33026\n",
      "[180]\ttrain-mlogloss:0.13683\teval-mlogloss:0.33044\n",
      "[181]\ttrain-mlogloss:0.13642\teval-mlogloss:0.33071\n",
      "[182]\ttrain-mlogloss:0.13603\teval-mlogloss:0.33112\n",
      "score:  0.9475\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "clf = xgboost\n",
    "train_matrix = clf.DMatrix(X_train, label=y_train, missing=-1)\n",
    "test_matrix = clf.DMatrix(X_test, label=y_test, missing=-1)\n",
    "z = clf.DMatrix(X_valid, label=y_valid, missing=-1)\n",
    "params = {\n",
    "    'booster': \"gbtree\",\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"min_child_weight\": 1.5,\n",
    "    \"max_depth\": 5,\n",
    "    \"lambda\": 10,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"colsample_bylevel\": 0.7,\n",
    "    \"eta\": 0.03,\n",
    "    \"tree_method\": \"exact\",\n",
    "    \"seed\": 2017,\n",
    "    \"num_class\": 2,\n",
    "}\n",
    "\n",
    "num_round = 10000\n",
    "early_stopping_rounds = 100\n",
    "watch_list = [(train_matrix, 'train'), (test_matrix, \"eval\")]\n",
    "model = clf.train(params, train_matrix, num_boost_round=num_round, evals=watch_list, early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "pre = model.predict(z, ntree_limit=model.best_ntree_limit)\n",
    "print(\"score: \", np.mean((pre[:, 1]>0.5)==y_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 自己封装模型\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}